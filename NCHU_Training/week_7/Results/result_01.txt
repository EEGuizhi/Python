# 2022/8/23 16:00

>> Using cuda device
>> Training...
x_train:
 tensor([[[[ 0.2863,  0.2863,  0.3098,  ...,  0.3961,  0.4039,  0.4196],
          [ 0.2941,  0.3020,  0.3176,  ...,  0.4039,  0.4118,  0.3961],
          [ 0.3020,  0.3255,  0.3333,  ...,  0.3961,  0.4118,  0.3882],
          ...,
          [ 0.6863,  0.6941,  0.7020,  ..., -0.2706, -0.2549, -0.2706],
          [ 0.7020,  0.6863,  0.6941,  ..., -0.2941, -0.2471, -0.3176],
          [ 0.7098,  0.7020,  0.6784,  ..., -0.3176, -0.2549, -0.2627]],

         [[ 0.4196,  0.4196,  0.4431,  ...,  0.4039,  0.4118,  0.4275],
          [ 0.4275,  0.4353,  0.4510,  ...,  0.4118,  0.4196,  0.4039],
          [ 0.4353,  0.4588,  0.4667,  ...,  0.4039,  0.4196,  0.3961],
          ...,
          [ 0.6392,  0.6471,  0.6471,  ..., -0.4118, -0.4039, -0.4118],
          [ 0.6314,  0.6392,  0.6471,  ..., -0.4353, -0.3882, -0.4510],
          [ 0.6471,  0.6392,  0.6314,  ..., -0.4431, -0.3804, -0.4039]],

         [[-0.6784, -0.6784, -0.6549,  ..., -0.6941, -0.6863, -0.6549],
          [-0.6706, -0.6627, -0.6314,  ..., -0.6863, -0.6784, -0.6784],
          [-0.6471, -0.6235, -0.6157,  ..., -0.6941, -0.6784, -0.7020],
          ...,
          [-0.0980, -0.0902, -0.0667,  ..., -0.9294, -0.9451, -1.0000],
          [-0.1137, -0.1137, -0.1059,  ..., -1.0000, -0.9686, -1.0000],
          [-0.1294, -0.1373, -0.1373,  ..., -1.0000, -0.9922, -0.9216]]],


        [[[-0.9137, -0.9686, -0.9529,  ..., -0.7647, -0.8039, -0.7569],
          [-0.8745, -0.8980, -0.9059,  ..., -0.7961, -0.8275, -0.8039],
          [-0.8980, -0.8824, -0.8745,  ..., -0.7882, -0.7882, -0.7412],
          ...,
          [-0.5451, -0.4196, -0.2471,  ..., -1.0000, -0.6706, -0.3725],
          [-0.0980, -0.4980, -0.3569,  ..., -0.8980, -0.5059, -0.3804],
          [-0.1843, -0.6627, -0.5608,  ..., -0.7098, -0.4275, -0.4353]],

         [[-0.8275, -0.8824, -0.8745,  ..., -0.6235, -0.6627, -0.6157],
          [-0.8118, -0.8353, -0.8196,  ..., -0.6706, -0.7020, -0.6627],
          [-0.8353, -0.8196, -0.8118,  ..., -0.6627, -0.6627, -0.6157],
          ...,
          [-0.4667, -0.3647, -0.2235,  ..., -0.9294, -0.5686, -0.2549],
          [-0.0275, -0.4431, -0.3255,  ..., -0.7569, -0.3490, -0.2000],
          [-0.1216, -0.6078, -0.5294,  ..., -0.5451, -0.2235, -0.2000]],

         [[-0.9373, -0.9922, -0.9608,  ..., -0.8275, -0.8667, -0.8196],
          [-0.9294, -0.9373, -0.9294,  ..., -0.8745, -0.9059, -0.8667],
          [-0.9529, -0.9373, -0.9137,  ..., -0.8667, -0.8667, -0.8196],
          ...,
          [-0.7569, -0.6314, -0.4667,  ..., -1.0000, -0.7255, -0.4824],
          [-0.2549, -0.7020, -0.5843,  ..., -0.9294, -0.6235, -0.5608],
          [-0.3020, -0.8510, -0.7882,  ..., -0.8039, -0.6000, -0.6863]]],


        [[[ 0.0745,  0.0745,  0.0745,  ...,  0.0824,  0.0902,  0.0902],
          [ 0.0745,  0.0745,  0.0745,  ...,  0.0824,  0.0902,  0.0980],
          [ 0.0745,  0.0745,  0.0745,  ...,  0.0824,  0.0824,  0.0980],
          ...,
          [ 0.4353,  0.4588,  0.2627,  ...,  0.0667, -0.0588, -0.2235],
          [ 0.3255,  0.4275,  0.3020,  ...,  0.1294,  0.1294, -0.0275],
          [ 0.2314,  0.2863,  0.3176,  ...,  0.1529,  0.1216,  0.0902]],

         [[-0.0039, -0.0039, -0.0039,  ..., -0.0118, -0.0196, -0.0196],
          [-0.0039, -0.0039, -0.0039,  ..., -0.0118, -0.0196, -0.0118],
          [-0.0039, -0.0039, -0.0039,  ..., -0.0118, -0.0118, -0.0039],
          ...,
          [ 0.2784,  0.3176,  0.1216,  ..., -0.0039, -0.1059, -0.2314],
          [ 0.1608,  0.2706,  0.1608,  ...,  0.0353,  0.0745, -0.0745],
          [ 0.0745,  0.1294,  0.1765,  ...,  0.0431,  0.0431,  0.0275]],

         [[-0.0824, -0.0824, -0.0824,  ..., -0.1216, -0.1216, -0.1216],
          [-0.0824, -0.0824, -0.0824,  ..., -0.1216, -0.1216, -0.1137],
          [-0.0824, -0.0824, -0.0824,  ..., -0.1216, -0.1216, -0.1294],
          ...,
          [ 0.0667,  0.1294, -0.0353,  ..., -0.1373, -0.2314, -0.3725],
          [-0.0824,  0.0745,  0.0039,  ..., -0.0745, -0.0510, -0.2000],
          [-0.1843, -0.0824,  0.0196,  ..., -0.0588, -0.0510, -0.0745]]],


        ...,


        [[[ 0.4353,  0.4353,  0.4353,  ...,  0.4353,  0.4353,  0.4431],
          [ 0.4431,  0.4431,  0.4431,  ...,  0.4431,  0.4431,  0.4431],
          [ 0.4510,  0.4510,  0.4431,  ...,  0.4431,  0.4431,  0.4431],
          ...,
          [ 0.4588,  0.4588,  0.4588,  ...,  0.4824,  0.4667,  0.4745],
          [ 0.4588,  0.4588,  0.4588,  ...,  0.4510,  0.4824,  0.4745],
          [ 0.4588,  0.4588,  0.4588,  ...,  0.5294,  0.4745,  0.4745]],

         [[ 0.4353,  0.4353,  0.4353,  ...,  0.4353,  0.4353,  0.4431],
          [ 0.4431,  0.4431,  0.4431,  ...,  0.4431,  0.4431,  0.4431],
          [ 0.4510,  0.4510,  0.4431,  ...,  0.4431,  0.4431,  0.4431],
          ...,
          [ 0.4588,  0.4588,  0.4588,  ...,  0.4824,  0.4667,  0.4745],
          [ 0.4588,  0.4588,  0.4588,  ...,  0.4510,  0.4824,  0.4745],
          [ 0.4588,  0.4588,  0.4588,  ...,  0.5294,  0.4745,  0.4745]],

         [[ 0.4353,  0.4353,  0.4353,  ...,  0.4353,  0.4353,  0.4431],
          [ 0.4431,  0.4431,  0.4431,  ...,  0.4431,  0.4431,  0.4431],
          [ 0.4510,  0.4510,  0.4431,  ...,  0.4431,  0.4431,  0.4431],
          ...,
          [ 0.4588,  0.4588,  0.4588,  ...,  0.4824,  0.4667,  0.4745],
          [ 0.4588,  0.4588,  0.4588,  ...,  0.4510,  0.4824,  0.4745],
          [ 0.4588,  0.4588,  0.4588,  ...,  0.5294,  0.4745,  0.4745]]],


        [[[ 0.9294,  0.9294,  0.9216,  ...,  0.9529,  0.9529,  0.9529],
          [ 0.9294,  0.9216,  0.9216,  ...,  0.9529,  0.9529,  0.9529],
          [ 0.9294,  0.9294,  0.9216,  ...,  0.9529,  0.9529,  0.9529],
          ...,
          [ 0.8588,  0.8667,  0.8667,  ...,  0.9373,  0.9373,  0.9373],
          [ 0.8588,  0.8588,  0.8667,  ...,  0.9373,  0.9373,  0.9373],
          [ 0.8588,  0.8588,  0.8667,  ...,  0.9373,  0.9373,  0.9373]],

         [[ 0.7804,  0.7804,  0.7882,  ...,  0.8196,  0.8196,  0.8196],
          [ 0.7804,  0.7882,  0.7882,  ...,  0.8196,  0.8196,  0.8196],
          [ 0.7804,  0.7804,  0.7882,  ...,  0.8196,  0.8196,  0.8196],
          ...,
          [ 0.6784,  0.6863,  0.6863,  ...,  0.8196,  0.8196,  0.8196],
          [ 0.6784,  0.6784,  0.6863,  ...,  0.8196,  0.8196,  0.8196],
          [ 0.6784,  0.6784,  0.6863,  ...,  0.8196,  0.8196,  0.8196]],

         [[ 0.4510,  0.4510,  0.4510,  ...,  0.4824,  0.4824,  0.4824],
          [ 0.4510,  0.4510,  0.4510,  ...,  0.4824,  0.4824,  0.4824],
          [ 0.4510,  0.4510,  0.4510,  ...,  0.4824,  0.4824,  0.4824],
          ...,
          [ 0.3490,  0.3569,  0.3569,  ...,  0.4824,  0.4824,  0.4824],
          [ 0.3490,  0.3490,  0.3569,  ...,  0.4824,  0.4824,  0.4824],
          [ 0.3490,  0.3490,  0.3569,  ...,  0.4824,  0.4824,  0.4824]]],


        [[[ 0.5137,  0.5137,  0.5137,  ..., -0.3020, -0.3176, -0.3490],
          [ 0.5216,  0.5137,  0.5137,  ..., -0.3176, -0.3255, -0.3490],
          [ 0.5216,  0.5137,  0.5137,  ..., -0.3255, -0.3412, -0.3569],
          ...,
          [-0.0745, -0.0980, -0.0980,  ..., -0.3647, -0.4039, -0.4118],
          [-0.0980, -0.0980, -0.0980,  ..., -0.3412, -0.3725, -0.3804],
          [-0.1059, -0.1373, -0.1451,  ..., -0.3020, -0.3333, -0.3333]],

         [[ 0.6392,  0.6392,  0.6392,  ..., -0.2471, -0.2627, -0.2941],
          [ 0.6471,  0.6392,  0.6392,  ..., -0.2627, -0.2706, -0.2941],
          [ 0.6471,  0.6392,  0.6392,  ..., -0.2706, -0.2863, -0.3020],
          ...,
          [-0.0667, -0.0902, -0.0902,  ..., -0.3255, -0.3647, -0.3961],
          [-0.0902, -0.0902, -0.0980,  ..., -0.3020, -0.3333, -0.3647],
          [-0.0980, -0.1373, -0.1216,  ..., -0.2627, -0.2941, -0.3176]],

         [[ 0.7647,  0.7647,  0.7647,  ..., -0.5922, -0.6078, -0.6392],
          [ 0.7725,  0.7647,  0.7647,  ..., -0.6078, -0.6157, -0.6392],
          [ 0.7725,  0.7647,  0.7647,  ..., -0.6000, -0.6314, -0.6471],
          ...,
          [-0.5373, -0.5451, -0.5451,  ..., -0.6392, -0.6784, -0.7020],
          [-0.5451, -0.5373, -0.5216,  ..., -0.6235, -0.6549, -0.6784],
          [-0.5451, -0.5608, -0.5373,  ..., -0.5843, -0.6157, -0.6314]]]])
outputs:
 tensor([233, 244, 197,  64, 363, 341,  79, 116,  96, 215, 284,  33,  47, 237,
        295, 130, 277, 269,  51, 150, 102,  28, 329, 365, 218, 217, 216, 358,
        109,  47, 161,   3, 263,  11, 257,  18, 152, 367, 390, 258, 116, 175,
        298, 255,  19, 345, 280, 343, 258, 182, 260,  51,  65, 220, 184,  90,
        102, 273, 165, 296,  38, 358, 342, 224, 360, 243, 389, 307, 145, 287,
        292, 338, 314, 399, 327, 245, 251, 174, 206,  45, 256, 188, 369, 202,
        216, 233, 115, 168, 345,  13,  62, 135, 147, 166, 331, 303,   1, 123,
        172, 185, 364, 377, 370, 201,  45, 363,  86, 293, 133, 188, 121,  23,
         43,  35, 220, 112,  57, 353, 366, 134, 234, 235, 286, 128, 325, 129,
         65, 320])
Traceback (most recent call last):
  File "d:\學校相關\大學專題\專題前訓練\week_7\week7_4109061012.py", line 88, in <module>
    y_train = model(x_train)
  File "C:\Users\danie\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl      
    return forward_call(*input, **kwargs)
  File "d:\學校相關\大學專題\專題前訓練\week_7\week7_4109061012.py", line 47, in forward
    x = self.net(x)
  File "C:\Users\danie\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl      
    return forward_call(*input, **kwargs)
  File "C:\Users\danie\AppData\Local\Programs\Python\Python39\lib\site-packages\torchvision\models\vgg.py", line 66, in forward
    x = self.features(x)
  File "C:\Users\danie\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl      
    return forward_call(*input, **kwargs)
  File "C:\Users\danie\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\container.py", line 139, in forward       
    input = module(input)
  File "C:\Users\danie\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl      
    return forward_call(*input, **kwargs)
  File "C:\Users\danie\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Users\danie\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\conv.py", line 453, in _conv_forward      
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory.
Tried to allocate 1.53 GiB (GPU 0; 4.00 GiB total capacity; 2.11 GiB already allocated; 643.83 MiB free; 2.13 GiB reserved in total by PyTorch)
If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.
See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
